---
title: "我们如何利用回收的低成本计算资源进行大规模的近线模型推断"
date: "2024-07-27 16:45:00" 
track: "streaming"
presenters: "Yun Tang"
stype: "中文演讲"
---
由于GPU资源的不断增值，我们对小红书的图像搜索系统进行了重构，创建了近线/离线推理管道，最终开发出一种高质量的节省成本和提高效率的解决方案，利用空闲的计算资源来处理数十亿数据规模的模型推理任务:

在具有潮汐特性的瞬时且易于驱逐的资源池中，我们建立了一个虚拟化的k8s集群，以启用Flink作业的提交。
我们与业务团队合作，将图像搜索系统的复杂推理管道(之前由10多个微服务组成)简化为几个PyFlink作业。
由于基于cpu的推理在BI领域比传统的数据处理慢得多，Flink的本地检查点机制不再适用。我们将自适应调度程序与自定义容错机制相结合，以确保瞬时资源的稳定和连续运行。
最终，我们显著提高了图像搜索数据管道的效率和稳定性，同时节省了数十万核心·天的固定资源。由于Flink集成了流和批处理功能，整个管道还统一了业务需求的近线和离线推理路径，在事务和社区算法等其他领域实现了成功。在未来，我们还考虑将推理能力与Ray集成，以支持更广泛的使用场景。
 ### Speakers: 
 <img src="https://sessionize.com/image/4849-400o400o1-LRkj3zMXkm7teij1dkn5Bs.jpg" width="200" /><br>Yun Tang:  流媒体引擎小红书技术负责人, 我有超过10年的大数据系统开发和研究经验，主要专注于实时计算(从Spark Streaming到Flink)。我于2017年加入阿里云，从事与Flink相关的开发任务，如状态管理、容错、生态系统集成等，并成为Flink社区的提交者。2022年，我加入小红书，担任实时计算团队负责人，负责推动集成流和批处理场景的采用，并在公司内部实施近线/离线机器学习推理解决方案。我也在探索像Ray这样的分布式计算系统。
 <br><br>